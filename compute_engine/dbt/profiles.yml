ais_dk:
  target: dev
  outputs:
    dev:
      job_execution_timeout_seconds: 300
      job_retries: 1
      keyfile: "../{{ env_var('GCP_PREFECT_JSON_LOCATION') }}" #Change this to dbt json
      location: "{{ env_var('GCP_REGION') }}"
      method: service-account
      priority: interactive
      project: "{{ env_var('GCP_PROJECT_ID') }}"
      schema: "dbt_{{ env_var('GCP_COMPUTE_USERNAME') }}" #Default bq-dataset for dbt to store data? Should use database?
      threads: 4
      type: bigquery
    prod:
      job_execution_timeout_seconds: 300
      job_retries: 1
      keyfile: "../{{ env_var('GCP_PREFECT_JSON_LOCATION') }}" #Change this to dbt json
      location: "{{ env_var('GCP_REGION') }}"
      method: service-account
      priority: interactive
      project: "{{ env_var('GCP_PROJECT_ID') }}"
      schema: production
      threads: 4
      type: bigquery